# Sentiment Analysis using Encoder Decoder architecture 

## Objective
* Take the last code  (+tweet dataset) and convert that in such a war that:
	* encoder: an RNN/LSTM layer takes the words in a sentence one by one and finally converts them into a single vector. VERY IMPORTANT TO MAKE THIS SINGLE VECTOR
	* this single vector is then sent to another RNN/LSTM that also takes the last prediction as its second input. Then we take the final vector from this Cell
	* and send this final vector to a Linear Layer and make the final prediction. 
	* This is how it will look:
		* embedding
		* word from a sentence +last hidden vector -> encoder -> single vector
		* single vector + last hidden vector -> decoder -> single vector
		* single vector -> FC layer -> Prediction
* Your code will be checked for plagiarism, and if we find that you have copied from the internet, then -100%. 
* The code needs to look as simple as possible, the focus is on making encoder/decoder classes and how to link objects together
* Getting good accuracy is NOT the target, but must achieve at least 45% or more
* Once the model is trained, take one sentence, "print the outputs" of the encoder for each step and "print the outputs" for each step of the decoder. ‚Üê THIS IS THE ACTUAL ASSIGNMENT

## The Network
![Network](https://user-images.githubusercontent.com/36162708/121363882-f0d72700-c954-11eb-8196-fe85493f22e9.jpg)

The Input text is preprocessed by removing a punctuations, Tokenized with spacy tokenizer and passed to embedding layer.

Embedding Dimensions = 300

then the embedded tokens(1 token at a step) are passed to a Encoder(LSTM) and at the end we have taken a **Context Vector** from the Encoder.

	Encoder(
		(encoder): LSTM(300, 100, batch_first=True)
	)

The **Context Vector** from the Encoder is given as one of the input for Decoder.

	Decoder(
		(decoder): LSTM(100, 100, batch_first=True)
	)
The predicted output from the Decoder is passed through a fully connected network with

**in_features** = 100

**out_features** = 3

Network:

     Classifier(
		(embedding): Embedding(4403, 300)
		(Encoder): Encoder(
			(encoder): LSTM(300, 100, batch_first=True)
		)
		(Decoder): Decoder(
			(decoder): LSTM(100, 100, batch_first=True)
		)
		(FCN): Linear(in_features=100, out_features=3, bias=True)
	)
	The model has 1,562,803 trainable parameters
      
 ### Training logs 
 
 	Epoch: 0 Train Loss: 1.057 | Train Acc: 65.83%  Val. Loss: 0.945 |  Val. Acc: 65.28%
	Epoch: 1 Train Loss: 0.911 | Train Acc: 68.54%  Val. Loss: 0.898 |  Val. Acc: 65.28%
	Epoch: 2 Train Loss: 0.831 | Train Acc: 71.52%  Val. Loss: 0.894 |  Val. Acc: 65.62%
	Epoch: 3 Train Loss: 0.808 | Train Acc: 76.61%  Val. Loss: 0.893 |  Val. Acc: 66.32% 
	Epoch: 4 Train Loss: 0.800 | Train Acc: 78.24%  Val. Loss: 0.892 |  Val. Acc: 66.01%
	Epoch: 5 Train Loss: 0.784 | Train Acc: 78.96%  Val. Loss: 0.900 |  Val. Acc: 63.93%
	Epoch: 6 Train Loss: 0.750 | Train Acc: 81.52%  Val. Loss: 0.885 |  Val. Acc: 65.67% 
      	. 
      	. 
      	. 
      	. 
      	. 
	Epoch: 195 Train Loss: 0.572 | Train Acc: 97.95% Val. Loss: 0.767 |  Val. Acc: 78.51%
	Epoch: 196 Train Loss: 0.572 | Train Acc: 97.95% Val. Loss: 0.767 |  Val. Acc: 78.51%
	Epoch: 197 Train Loss: 0.572 | Train Acc: 97.95% Val. Loss: 0.768 |  Val. Acc: 78.51%
	Epoch: 198 Train Loss: 0.571 | Train Acc: 98.04% Val. Loss: 0.769 |  Val. Acc: 78.17%
	Epoch: 199 Train Loss: 0.571 | Train Acc: 98.04% Val. Loss: 0.769 |  Val. Acc: 78.17% 


### Results

      Minimum Train Loss: 0.571  
      Minimum Validation Loss: 0.755
   
   
      Maximum Train Accuracy: 98.04 %   
      Maximum Validation Accuracy: 78.51 % 
   
![loss](https://user-images.githubusercontent.com/36162708/121363950-fdf41600-c954-11eb-8862-15e0f4ede91a.jpg)
![acc](https://user-images.githubusercontent.com/36162708/121364238-3bf13a00-c955-11eb-9fd7-20bb27788306.jpg)


   
### Outcomes:

   #### Correct Prediction
   
      Sample Tweet: Obama's Gender Advantage Extends to the States - 2012 Decoded: New detail on recent swing state polling further ... http://t.co/8iSanDGS
      Actual Value: Positive
      Predicted Value: Positive
      
      Sample Tweet: In his teen years, Obama has been known to use marijuana and cocaine.
      Actual Value: Negative
      Predicted Value: Negative
      
      Sample Tweet: #WhatsRomneyHiding? Obama's dignity and sense of humor? #p2 #tcot
      Actual Value: Neutral
      Predicted Value: Neutral
   
 #### Wrong Prediction
      
      Sample Tweet: Obama needs remedial course in judicial review.Read at http://t.co/wX1RzFKm #twisters #tcot #tpp #sgp #tlot #vettheprez #lnyhbt #withnewt
      Actual Value: Negative
      Predicted Value: Positive
      
      Sample Tweet: RT@pslweb Endorsement Of Democrats: A Misuse Of Union Time And Money http://t.co/l3QGcWds #union #ilwu #seiu #aflcio #demproxy #union #alba
      Actual Value: Positive
      Predicted Value: Negative
      
      Sample Tweet: RT @LiberalMel: REPUBLICANS WANT TO TAKE AWAY FREE HEALTHCARE AND SEND PUT PEOPLE IN JAIL FOR FIGHTING. REPUBLICANS ARE AHOLES!!! #DEM #OBAMA #OBAMA2012
      Actual Value: Positive
      Predicted Value: Negative
      
 ## Encoder and Decoder outputs
 
  	Tweet: In his teen years, Obama has been known to use marijuana and cocaine.	
	Preprocessed: In his teen years Obama has been known to use marijuana and cocaine	
 	tensor([[ 69,  27, 142,  60,   2,  46,  92, 130,   7, 110, 139,  16, 136]])
	
    	Embeddings:
 	tensor([[[ 1.2053,  0.3439, -0.2684,  ..., -1.1779,  0.2601, -0.9633],
         [-1.7533, -1.7126, -1.2845,  ..., -0.6122,  0.5829, -0.5771],
         [ 0.0614,  1.4275,  1.7948,  ...,  0.2213,  0.6731,  0.0191],
         ...,
         [-1.3191, -1.1021, -2.1896,  ...,  0.7818, -1.5764,  0.4521],
         [-1.7134,  0.1199, -0.2856,  ..., -0.9255, -0.7704, -0.4345],
         [ 1.5614,  0.0087,  0.5109,  ..., -1.1690,  1.4251,  0.6806]]],
       	grad_fn=<EmbeddingBackward>)
			
	Encoder Output step:0
 	tensor([[[ 0.0618,  0.0586,  0.1360,  0.3512,  0.2561,  0.2030,  0.1514,
          -0.2256,  0.0858,  0.1152,  0.0099,  0.2734, -0.0645, -0.0771,
           0.1537, -0.0551, -0.1538, -0.4869,  0.0823, -0.0316, -0.0276,
          -0.0036, -0.0493,  0.1156,  0.0802, -0.2285, -0.0404, -0.0480,
           0.0675,  0.0031, -0.0200, -0.1295,  0.3023,  0.2877, -0.4928,
          -0.1789, -0.0314,  0.0573,  0.3053,  0.4829, -0.0988,  0.0451,
           0.3335,  0.1299,  0.1248, -0.2656, -0.2034, -0.0605,  0.1131,
           0.2372,  0.3119, -0.0196, -0.0367, -0.0959, -0.1621,  0.3305,
          -0.2709,  0.3645,  0.2246,  0.2796,  0.0161,  0.0785,  0.1228,
           0.0029,  0.1474,  0.0986, -0.0433, -0.1086, -0.1197, -0.0980,
          -0.3607,  0.1017, -0.3660, -0.0884,  0.1517,  0.3106,  0.0296,
           0.0593, -0.0829, -0.0282, -0.1188,  0.2333,  0.1426, -0.4237,
          -0.1441,  0.0439,  0.0617,  0.2828,  0.1812,  0.0043,  0.1308,
          -0.1355,  0.0157, -0.0202, -0.4434, -0.0228,  0.0464, -0.4259,
          -0.2439,  0.0264]]], grad_fn=<StackBackward>)
	  
	Encoder Output step:1
 	tensor([[[ 0.3386,  0.2312,  0.5519, -0.0118, -0.0730,  0.1149,  0.2753,
          -0.2420,  0.1873, -0.1124, -0.2037, -0.0316, -0.2008, -0.1687,
           0.0743, -0.0556,  0.0271,  0.1772, -0.0111, -0.2384, -0.1676,
          -0.1074, -0.3762,  0.3130,  0.5292, -0.0440, -0.0366,  0.2598,
           0.4038,  0.1407, -0.1668, -0.3062,  0.2529,  0.1477, -0.0431,
          -0.4786, -0.2433,  0.0963,  0.2424,  0.5579,  0.1184, -0.1089,
           0.2885, -0.2694,  0.0548,  0.1622,  0.1634, -0.2612, -0.0195,
          -0.0116, -0.0569, -0.0495, -0.0498, -0.2712, -0.1466,  0.2090,
          -0.4761,  0.1665,  0.0154, -0.1139,  0.5168,  0.1729,  0.0949,
           0.1575,  0.3380,  0.0947,  0.1007,  0.2572, -0.2071, -0.1246,
          -0.1929, -0.1317, -0.0173, -0.1029,  0.6391,  0.2848, -0.5092,
           0.5449, -0.1120, -0.1636, -0.0943,  0.3989,  0.2692, -0.5244,
          -0.0290, -0.0304,  0.0402, -0.1208,  0.0711,  0.0754,  0.7369,
           0.0531,  0.2017, -0.1078, -0.4456,  0.1415,  0.0751, -0.0413,
           0.0557, -0.0741]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:2
 	tensor([[[-0.0326,  0.5326,  0.2998,  0.2381,  0.1991,  0.6365,  0.0209,
          -0.0309, -0.0195, -0.1511, -0.5517, -0.2802, -0.4564, -0.3943,
           0.5115, -0.0313, -0.0678,  0.0698,  0.0212, -0.2910, -0.5224,
          -0.4910, -0.4291,  0.4004,  0.8191,  0.0572, -0.3572,  0.4369,
           0.0930,  0.3393, -0.4116, -0.1867,  0.5854,  0.3125,  0.3959,
          -0.4798, -0.1426,  0.3251,  0.4596,  0.7376,  0.3271, -0.3584,
           0.4266,  0.1238,  0.3917,  0.2467,  0.1742,  0.2089,  0.1882,
           0.1350, -0.0748, -0.1950, -0.2723, -0.5570, -0.6686,  0.4855,
           0.1314,  0.4634,  0.1812,  0.0034,  0.2996,  0.2495, -0.0818,
           0.3690,  0.2520,  0.0972, -0.2799, -0.3667, -0.2113, -0.5018,
          -0.1394, -0.1890,  0.0222,  0.2693,  0.6302,  0.2862, -0.1465,
           0.3542, -0.1522, -0.0942, -0.7360,  0.3252,  0.0420, -0.6653,
          -0.0605,  0.1411,  0.0257, -0.5243, -0.0253, -0.0261,  0.7323,
          -0.4027, -0.1595, -0.1358, -0.2234, -0.2701,  0.0023, -0.4397,
           0.6987,  0.0960]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:3
	 tensor([[[-0.1199,  0.1177,  0.2792,  0.1217,  0.1557,  0.2623,  0.2144,
           0.3271,  0.4120, -0.4179, -0.1246, -0.1345, -0.5473,  0.0099,
           0.4372, -0.3767,  0.1542, -0.4756, -0.0125, -0.4782, -0.0432,
          -0.5220,  0.0633,  0.1744,  0.3206,  0.3739, -0.0774,  0.4026,
           0.3152, -0.1579, -0.0851,  0.3586,  0.2362,  0.2276,  0.4822,
          -0.2301, -0.4505,  0.1677,  0.6080,  0.4951,  0.4449, -0.1740,
          -0.2955,  0.0893,  0.1349,  0.3878, -0.0393,  0.2055,  0.0917,
           0.3807, -0.0128, -0.6692, -0.3326,  0.4535, -0.7907,  0.4051,
           0.0778,  0.3969,  0.3293, -0.3581, -0.1176,  0.2977,  0.0088,
           0.4741,  0.5408, -0.0311, -0.0529, -0.3881, -0.2632, -0.4845,
          -0.0023, -0.1143, -0.2745,  0.3269,  0.3004,  0.1750, -0.1388,
           0.1973, -0.2757, -0.0014, -0.2115,  0.5151, -0.3885, -0.6099,
           0.1420,  0.3155, -0.4154, -0.1263,  0.0205, -0.5852,  0.1173,
          -0.5932,  0.0108, -0.1984, -0.3897,  0.1984, -0.2149, -0.4576,
          -0.0499,  0.0347]]], grad_fn=<StackBackward>)
	  
	Encoder Output step:4
 	tensor([[[-0.3729, -0.4324,  0.3752, -0.0239,  0.4070,  0.3501,  0.1198,
           0.7142,  0.1734, -0.3318, -0.1662, -0.0964, -0.4853, -0.3345,
           0.4696, -0.5262,  0.2140,  0.0492, -0.1527,  0.1094,  0.0599,
          -0.1011,  0.1575,  0.1068,  0.1703,  0.1485,  0.0290,  0.5142,
           0.4986,  0.2947, -0.3073,  0.1314,  0.0278,  0.2390, -0.1739,
          -0.6894, -0.6557,  0.5348,  0.6571,  0.6135,  0.2939, -0.2635,
          -0.3896, -0.0230,  0.5921,  0.0234, -0.1981,  0.5045, -0.1673,
           0.2090, -0.5138, -0.4368, -0.2236, -0.2701,  0.0023,  0.6012,
           0.1978,  0.4986,  0.5186,  0.2599,  0.2314,  0.6870,  0.0462,
           0.1517,  0.5347,  0.4176,  0.0807,  0.0824, -0.2646, -0.4807,
          -0.4900, -0.6830,  0.1122,  0.2526,  0.6872,  0.3270, -0.3057,
          -0.0762,  0.1035, -0.1905, -0.1386,  0.8077, -0.7636, -0.4943,
           0.6225,  0.0165, -0.1056, -0.0074, -0.0049, -0.6582,  0.5978,
          -0.3302, -0.1372, -0.1317, -0.8726,  0.2312, -0.2821, -0.0774,
          -0.1537,  0.0029]]], grad_fn=<StackBackward>)
	  
	Encoder Output step:5
 	tensor([[[-0.6380,  0.1452,  0.2781, -0.1500,  0.3459,  0.4335,  0.3173,
           0.1282, -0.0259, -0.6351,  0.1655, -0.2915, -0.0031,  0.1907,
           0.0932, -0.8105,  0.1723, -0.3390, -0.0943,  0.3674,  0.1748,
          -0.0173,  0.2858,  0.3754,  0.4622, -0.3019,  0.0248,  0.3194,
          -0.0166,  0.0459, -0.1378,  0.5062,  0.1927, -0.2872, -0.0631,
          -0.1895, -0.1423,  0.7956,  0.1538, -0.1151,  0.3782, -0.4299,
          -0.6848, -0.2061,  0.2253,  0.2529, -0.1722, -0.0666, -0.1283,
           0.3139, -0.2574, -0.2051, -0.3423, -0.4602, -0.3420,  0.3256,
           0.2028,  0.4623,  0.5005, -0.0185,  0.4659,  0.7406, -0.0085,
           0.7873,  0.4826, -0.3006, -0.1207, -0.0965, -0.0517, -0.6875,
           0.0732, -0.3821,  0.0642,  0.6183,  0.6493, -0.0437, -0.5372,
          -0.0040, -0.1314, -0.2082, -0.3208, -0.0756, -0.4830, -0.5927,
          -0.0427, -0.2477, -0.2575, -0.3359, -0.0852, -0.4292,  0.3211,
           0.0418, -0.5503,  0.3461, -0.5279,  0.3715, -0.3440, -0.4807,
           0.1686, -0.2131]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:6
 	tensor([[[-0.5219,  0.8282,  0.4960, -0.2004,  0.5660,  0.5670,  0.1996,
           0.4331,  0.3884, -0.5256, -0.1589, -0.1687, -0.4803, -0.0835,
          -0.3476, -0.3009,  0.4221,  0.0032, -0.0098,  0.0656,  0.4269,
          -0.0667,  0.1816,  0.0056,  0.7185, -0.2796, -0.2065,  0.3313,
           0.0448, -0.2487, -0.3587,  0.2727,  0.2536, -0.4807, -0.2184,
          -0.4144, -0.2007,  0.7329,  0.5998, -0.4552,  0.1447, -0.1475,
          -0.5609, -0.3309,  0.6399,  0.3153, -0.5390,  0.2578, -0.0632,
           0.4065, -0.5805, -0.2443, -0.5984, -0.6221, -0.7528,  0.5246,
           0.1745,  0.8545,  0.5957, -0.0062, -0.0556,  0.5694, -0.3289,
           0.8809,  0.4273,  0.2343, -0.1666,  0.3238, -0.4238, -0.4301,
           0.4288, -0.0769,  0.3097,  0.3479,  0.5457,  0.0019, -0.3560,
          -0.0709, -0.1791,  0.3859, -0.0253,  0.1368, -0.6326, -0.1617,
           0.1682,  0.2072, -0.4777, -0.4698, -0.4135, -0.5441,  0.1601,
          -0.1088, -0.6762,  0.1889, -0.6207,  0.3382, -0.6186, -0.5566,
           0.1036,  0.0552]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:7
 	tensor([[[-0.3351,  0.8124,  0.5083, -0.1528,  0.2729,  0.3428,  0.5831,
           0.2631,  0.3759, -0.4471, -0.2180,  0.0387, -0.4723, -0.4883,
          -0.6370, -0.4914,  0.6849,  0.2853, -0.0028, -0.3349, -0.0975,
           0.0509,  0.1408,  0.5206,  0.3653, -0.0624,  0.1454,  0.3310,
           0.0721,  0.1092, -0.0636,  0.2556,  0.0142,  0.0715, -0.1291,
          -0.0850, -0.0831,  0.7228,  0.4835,  0.4396, -0.1717, -0.5997,
          -0.4743, -0.5318,  0.7074, -0.2064, -0.7943, -0.2092, -0.0863,
           0.1323, -0.8225, -0.5795, -0.6025, -0.2302, -0.8332,  0.5274,
           0.8186,  0.8479,  0.2539,  0.6019, -0.2760,  0.8824, -0.1976,
           0.3534,  0.2094, -0.1880, -0.1031,  0.0744, -0.2592, -0.4322,
           0.7575, -0.0604,  0.4238,  0.2856,  0.2300,  0.2800, -0.6012,
           0.2085,  0.1542,  0.2079, -0.3381,  0.7305, -0.6920, -0.3903,
           0.5999,  0.5696, -0.5174, -0.1312, -0.1047, -0.2538,  0.3575,
          -0.1801, -0.8303,  0.2459, -0.5881,  0.5504, -0.7110, -0.3756,
           0.3821, -0.1766]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:8
 	tensor([[[-0.3237,  0.6457,  0.5480, -0.3026, -0.0126,  0.4246,  0.7638,
           0.2705,  0.0718, -0.3928,  0.0280, -0.2021, -0.3912, -0.4940,
          -0.5538, -0.8146,  0.3459,  0.1635,  0.0112, -0.5773, -0.2593,
          -0.1636,  0.3497,  0.6222,  0.3131,  0.1251, -0.0435,  0.5211,
          -0.0291, -0.0577, -0.2694,  0.6086, -0.0783, -0.5524, -0.3244,
          -0.3257, -0.1554,  0.6634,  0.6663, -0.1775,  0.0374, -0.4741,
          -0.8372, -0.7455,  0.5305, -0.1503, -0.4379,  0.5806,  0.1787,
           0.1361, -0.2223, -0.0999, -0.6972, -0.5170, -0.7270,  0.2190,
           0.8487,  0.7108,  0.5018,  0.1019, -0.3428,  0.6692, -0.1469,
           0.8627,  0.4929,  0.4004, -0.1142,  0.3145, -0.4237, -0.4669,
           0.8015, -0.2720, -0.1990,  0.1587,  0.3262,  0.5524, -0.4949,
           0.0325,  0.2730,  0.1613, -0.4132,  0.4130, -0.3003, -0.1474,
           0.4912,  0.6365, -0.3538, -0.5288, -0.1734, -0.8193,  0.4797,
           0.0494, -0.7607, -0.1174, -0.4267,  0.7848, -0.4288, -0.4968,
           0.7626,  0.4474]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:9
 	tensor([[[-0.6702,  0.0695,  0.6023, -0.6093, -0.1169,  0.1023,  0.3600,
           0.2244,  0.0604, -0.3954,  0.0272, -0.1351, -0.6065, -0.0590,
          -0.8143, -0.7059, -0.0623,  0.0926,  0.0480, -0.8567, -0.3798,
          -0.3144,  0.7427, -0.0335,  0.6202,  0.1258, -0.4170,  0.4380,
          -0.0891,  0.2913, -0.4145, -0.0688,  0.3931, -0.5070, -0.2885,
           0.0015, -0.3114,  0.8152,  0.1784,  0.0432,  0.1786, -0.0478,
          -0.4276, -0.7304,  0.4455, -0.5506, -0.7295,  0.1523,  0.0424,
           0.3025, -0.5772, -0.0976, -0.1131,  0.0806, -0.8198,  0.4695,
           0.8142,  0.9120,  0.0691,  0.7206,  0.2626,  0.6167, -0.2043,
           0.7215, -0.1189, -0.1371,  0.0184,  0.3138, -0.0566, -0.0854,
           0.7634, -0.3724,  0.0561,  0.4158,  0.5015, -0.2770, -0.2951,
           0.2516,  0.0744,  0.0819, -0.1403,  0.1237, -0.4186, -0.1963,
           0.3485,  0.2916, -0.6427, -0.5373, -0.4362, -0.4303,  0.3694,
          -0.4190, -0.1048,  0.0549, -0.5956,  0.8924,  0.1215, -0.7575,
           0.5711, -0.0077]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:10
 	tensor([[[-0.8749,  0.3885,  0.5192, -0.6492,  0.0858,  0.1964,  0.2840,
           0.7331,  0.4608, -0.1957, -0.2295, -0.1241, -0.2105, -0.2711,
          -0.0560, -0.5409,  0.5528,  0.2819,  0.2201, -0.6147, -0.2485,
          -0.3860, -0.0210, -0.0702,  0.2093,  0.4715, -0.1936,  0.2080,
           0.2077,  0.6240, -0.3221, -0.0965, -0.2465, -0.8990, -0.7646,
          -0.1030, -0.5062,  0.9271,  0.7786, -0.2570,  0.1173, -0.4133,
          -0.8835, -0.2998,  0.8402, -0.0102, -0.3048,  0.2303,  0.3173,
           0.6838, -0.0773,  0.0356, -0.7733, -0.4428, -0.6154,  0.5354,
           0.9167,  0.8239,  0.4372,  0.0444,  0.5625,  0.9051, -0.3519,
           0.7327, -0.0482, -0.2873, -0.3794,  0.5928,  0.1411, -0.4381,
           0.9432, -0.2726, -0.0661,  0.3766,  0.0926, -0.2986, -0.3735,
           0.3618, -0.1952,  0.1299, -0.4306,  0.3181, -0.7377, -0.3392,
           0.7805,  0.6408, -0.4805, -0.7518, -0.2077, -0.7784,  0.3047,
          -0.5562, -0.6933,  0.4553,  0.0635,  0.8709, -0.1608, -0.0927,
           0.4379, -0.3576]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:11
 	tensor([[[-0.6816,  0.4207,  0.7037, -0.3897,  0.2475,  0.2149,  0.7987,
           0.1177,  0.5383, -0.3784, -0.4188, -0.3289, -0.4943, -0.7013,
           0.3147, -0.3831, -0.4676,  0.6069,  0.6002,  0.0118, -0.3229,
          -0.0406, -0.3030,  0.1504,  0.5180,  0.5787,  0.0464,  0.5105,
           0.4270,  0.8009, -0.1734, -0.0430, -0.4034, -0.7096, -0.2388,
           0.1423, -0.0871,  0.8112,  0.5178,  0.0987, -0.0472, -0.1415,
          -0.3128,  0.1163,  0.2617,  0.1695, -0.0983,  0.0753, -0.2954,
           0.8470, -0.5596,  0.0920, -0.4266, -0.6437, -0.7353,  0.6313,
           0.8730,  0.8030,  0.6211,  0.3636,  0.4952,  0.8068, -0.3960,
           0.9371, -0.0118,  0.0462, -0.2166,  0.3484, -0.0326, -0.2080,
           0.6076,  0.1826, -0.4426,  0.3084,  0.1265, -0.6352, -0.3283,
           0.2567, -0.4178,  0.3538, -0.7534,  0.4639, -0.5439, -0.3747,
           0.2775,  0.5251, -0.3476, -0.4493, -0.1069, -0.2044,  0.3112,
          -0.5935, -0.3566,  0.1775, -0.0887,  0.9470, -0.1856, -0.1035,
           0.7524, -0.2415]]], grad_fn=<StackBackward>)
	   
	Encoder Output step:12
 	tensor([[[-0.7597,  0.8098,  0.7980, -0.4128,  0.4630,  0.6558,  0.8730,
           0.7274,  0.0641, -0.7426, -0.5759, -0.5173, -0.5569, -0.6175,
          -0.1930, -0.7466,  0.1062,  0.3283,  0.5942,  0.0697, -0.6308,
           0.0841, -0.1227,  0.0379,  0.4596,  0.6682,  0.1905,  0.6858,
           0.4318,  0.8984, -0.5304,  0.0703,  0.0173, -0.7748, -0.2919,
          -0.5390, -0.2915,  0.7173,  0.7882,  0.5911, -0.3977, -0.4905,
          -0.3226,  0.1648,  0.5480,  0.0617, -0.2632,  0.4259, -0.1359,
           0.6431, -0.5778, -0.1742, -0.4276, -0.5708, -0.7712,  0.8520,
           0.8397,  0.8812,  0.7474,  0.2949,  0.4199,  0.9627, -0.7799,
           0.9333,  0.5013,  0.4941, -0.5612,  0.5278, -0.4143, -0.0096,
           0.4743, -0.1965, -0.4287,  0.5488,  0.2155, -0.2952, -0.2568,
           0.3156, -0.1044,  0.7834, -0.6638,  0.6524, -0.6484, -0.1709,
           0.7831,  0.5944, -0.5037, -0.6825, -0.4382, -0.3734,  0.0088,
          -0.4012,  0.0643, -0.1155, -0.5127,  0.8503, -0.0269, -0.4996,
           0.4511, -0.8216]]], grad_fn=<StackBackward>)
	   
	Context Vector:
 	tensor([[[-0.7597,  0.8098,  0.7980, -0.4128,  0.4630,  0.6558,  0.8730,
           0.7274,  0.0641, -0.7426, -0.5759, -0.5173, -0.5569, -0.6175,
          -0.1930, -0.7466,  0.1062,  0.3283,  0.5942,  0.0697, -0.6308,
           0.0841, -0.1227,  0.0379,  0.4596,  0.6682,  0.1905,  0.6858,
           0.4318,  0.8984, -0.5304,  0.0703,  0.0173, -0.7748, -0.2919,
          -0.5390, -0.2915,  0.7173,  0.7882,  0.5911, -0.3977, -0.4905,
          -0.3226,  0.1648,  0.5480,  0.0617, -0.2632,  0.4259, -0.1359,
           0.6431, -0.5778, -0.1742, -0.4276, -0.5708, -0.7712,  0.8520,
           0.8397,  0.8812,  0.7474,  0.2949,  0.4199,  0.9627, -0.7799,
           0.9333,  0.5013,  0.4941, -0.5612,  0.5278, -0.4143, -0.0096,
           0.4743, -0.1965, -0.4287,  0.5488,  0.2155, -0.2952, -0.2568,
           0.3156, -0.1044,  0.7834, -0.6638,  0.6524, -0.6484, -0.1709,
           0.7831,  0.5944, -0.5037, -0.6825, -0.4382, -0.3734,  0.0088,
          -0.4012,  0.0643, -0.1155, -0.5127,  0.8503, -0.0269, -0.4996,
           0.4511, -0.8216]]], grad_fn=<ViewBackward>)
	   
	Decoder OP:
 	tensor([[[-0.4676, -0.4444, -0.5333, -0.5014, -0.5716,  0.5036,  0.1332,
          -0.1049, -0.4936, -0.5259,  0.5034,  0.4295, -0.5055,  0.2776,
          -0.4793, -0.3676, -0.3783, -0.5725,  0.5545, -0.1808, -0.3362,
           0.4007,  0.5332,  0.5317, -0.5045,  0.4959, -0.5785,  0.4753,
          -0.5039,  0.5390, -0.4096,  0.5311,  0.5551,  0.4047, -0.5636,
          -0.4425, -0.5110,  0.5170,  0.4707, -0.5431, -0.5072, -0.5641,
           0.4988, -0.3774,  0.0887, -0.4923, -0.5307, -0.5915, -0.5246,
          -0.6034, -0.5628,  0.5690,  0.3027, -0.4998, -0.5109, -0.3795,
           0.4935, -0.5387,  0.4682,  0.5726,  0.3612, -0.5848, -0.4985,
          -0.5925, -0.1727, -0.3595, -0.5572, -0.1312, -0.4898,  0.5963,
           0.4045,  0.5586, -0.5414,  0.4862,  0.5961,  0.3631,  0.3199,
           0.5602,  0.5661, -0.4661, -0.5752,  0.6089, -0.6508,  0.6218,
          -0.5880,  0.5062, -0.6327, -0.5452, -0.5113,  0.5108,  0.5937,
          -0.5322, -0.0999,  0.0844, -0.4851,  0.4132,  0.5100, -0.4051,
          -0.6031, -0.5648]]], grad_fn=<StackBackward>)
	  
	Prediction:
	'Positive'
      
      


